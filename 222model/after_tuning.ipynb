{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from hyperopt import fmin, tpe, hp, anneal, Trials\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import pickle\n",
    "\n",
    "# 調完參數後，讀取history，找出最佳參數，再訓練成新模型，存成pickle\n",
    "def get_optimal_parameter(history_file):\n",
    "    optimal_parameter = pd.read_csv(history_file).sort_values('loss').iloc[0]\n",
    "    return optimal_parameter.to_dict()\n",
    "\n",
    "\n",
    "# 實際再訓練一次模型\n",
    "def train_with_optimal_parameter(optimal_parameter):\n",
    "    init = optimal_parameter[\"init\"]\n",
    "    min_samples_split = optimal_parameter[\"min_samples_split\"]\n",
    "    learning_rate = optimal_parameter[\"learning_rate\"]\n",
    "    max_depth = optimal_parameter[\"max_depth\"]\n",
    "    min_samples_leaf = optimal_parameter[\"min_samples_leaf\"]\n",
    "    n_estimators = optimal_parameter[\"n_estimators\"]\n",
    "\n",
    "    if init == \"True\":\n",
    "        init_estimator = Ridge()\n",
    "        init_estimator.fit(X_train, Y_train)\n",
    "\n",
    "    else:\n",
    "        init_estimator = None\n",
    "\n",
    "    gbm = GradientBoostingRegressor(init=init_estimator,\n",
    "                    min_samples_split=min_samples_split,\n",
    "                    learning_rate=learning_rate,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_leaf=min_samples_leaf,\n",
    "                    max_features='sqrt',\n",
    "                    loss='huber',\n",
    "                    subsample=0.8,\n",
    "                    random_state=50,\n",
    "                    n_estimators=n_estimators,\n",
    "                    verbose=1)\n",
    "\n",
    "\n",
    "    gbm.fit(X_train, Y_train)\n",
    "    return gbm\n",
    "\n",
    "# 沒有調參數的模型\n",
    "def train_without_optimal_parameter():\n",
    "    init_estimator = Ridge()\n",
    "    init_estimator.fit(X_train, Y_train)\n",
    "    if county_name == '台北':\n",
    "        gbm = GradientBoostingRegressor(min_samples_split=0.09, learning_rate=0.1, max_depth=7,\n",
    "                                        min_samples_leaf=2,  max_features='sqrt', loss='huber',\n",
    "                                        subsample=0.8, random_state=50, n_estimators=2000, verbose=1)\n",
    "    elif county_name == '新北':\n",
    "        gbm = GradientBoostingRegressor(init=init_estimator, min_samples_split=0.1, learning_rate=0.3, max_depth=12,\n",
    "                                        min_samples_leaf=3,  max_features='sqrt', loss='huber',\n",
    "                                        subsample=0.8, random_state=50, n_estimators=1600, verbose=1)\n",
    "    elif county_name == '嘉義':\n",
    "        gbm = GradientBoostingRegressor(min_samples_split=0.0109, learning_rate=0.03,\n",
    "                                        max_depth=8, min_samples_leaf=5,  max_features='sqrt',\n",
    "                                        subsample=0.8, random_state=50, n_estimators=600, verbose=1)\n",
    "    elif county_name == '基隆':\n",
    "        gbm = GradientBoostingRegressor(min_samples_split=0.1, learning_rate=0.05, max_depth=9,\n",
    "                                        min_samples_leaf=5,  max_features='sqrt', loss='huber',\n",
    "                                        subsample=0.8, random_state=50, n_estimators=1600, verbose=1)\n",
    "    \n",
    "    elif county_name == '桃園':\n",
    "        gbm = GradientBoostingRegressor(init=init_estimator, min_samples_split=0.14, learning_rate=0.15, max_depth=11,\n",
    "                                        min_samples_leaf=2,  max_features='sqrt', loss='huber',\n",
    "                                        subsample=0.8, random_state=50, n_estimators=1800, verbose=1)\n",
    "    elif county_name == '台中':\n",
    "        gbm = GradientBoostingRegressor(init=init_estimator, min_samples_split=0.1, learning_rate=0.3, max_depth=10,\n",
    "                                        min_samples_leaf=5,  max_features='sqrt', loss='huber',\n",
    "                                        subsample=0.8, random_state=50, n_estimators=1400, verbose=1)\n",
    "    elif county_name == '台南':\n",
    "        gbm = GradientBoostingRegressor(init=init_estimator, min_samples_split=0.05, min_samples_leaf=5, max_depth=11,\n",
    "                                        max_features='sqrt', subsample=0.8, random_state=50,\n",
    "                                        learning_rate=0.02, n_estimators=1800, verbose=1)\n",
    "    elif county_name == '高雄':\n",
    "        gbm = GradientBoostingRegressor(init=init_estimator, min_samples_split=0.1, learning_rate=0.2, max_depth=9,\n",
    "                                        min_samples_leaf=2,  max_features='sqrt', loss='huber',\n",
    "                                        subsample=0.8, random_state=50, n_estimators=1600, verbose=1)\n",
    "    elif county_name == '新竹':\n",
    "        gbm = GradientBoostingRegressor(min_samples_split=0.1, learning_rate=0.15, max_depth=8,\n",
    "                                        min_samples_leaf=4,  max_features='sqrt', loss='huber',\n",
    "                                        subsample=0.8, random_state=50, n_estimators=1000, verbose=1)\n",
    "\n",
    "    gbm.fit(X_train, Y_train)\n",
    "    return gbm\n",
    "\n",
    "def read_df(county_name):\n",
    "    PATH = '.\\\\data'\n",
    "    X_train = pd.read_csv(Path(PATH)/f\"{county_name}_X_train.csv\")\n",
    "    Y_train = pd.read_csv(Path(PATH)/f\"{county_name}_Y_train.csv\")\n",
    "    X_test = pd.read_csv(Path(PATH)/f\"{county_name}_X_test.csv\")\n",
    "    Y_test = pd.read_csv(Path(PATH)/f\"{county_name}_Y_test.csv\")\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "if not os.path.exists('./optimal_models'):\n",
    "    os.mkdir('./optimal_models')\n",
    "if not os.path.exists('./non_optimal_models'):\n",
    "    os.mkdir('./non_optimal_models')\n",
    "\n",
    "county_name_list = ['台北','桃園','高雄','基隆','新竹','新北']\n",
    "# county_name = '台北' \n",
    "for county_name in county_name_list:\n",
    "    X_train, Y_train, X_test, Y_test = read_df(county_name)\n",
    "\n",
    "    # 訓練前要去掉raw_time\n",
    "    X_train = X_train.drop(columns=['raw_time'])\n",
    "    X_test = X_test.drop(columns=['raw_time'])\n",
    "    Y_train = Y_train.drop(columns=['raw_time'])\n",
    "    Y_test = Y_test.drop(columns=['raw_time'])\n",
    "\n",
    "    # 選擇要用的history file (原始版本 或 使用修改後的validation set版本)\n",
    "    # history_file = Path('.\\\\history_tuning')/Path(f\"{county_name}result.csv\")\n",
    "    history_file = Path('.\\\\history_tuning\\\\use_better_validation')/Path(f\"{county_name}result.csv\")\n",
    "    optimal_parameter = get_optimal_parameter(history_file)\n",
    "\n",
    "    # 做調參數模型\n",
    "    optimal_model = train_with_optimal_parameter(optimal_parameter)\n",
    "    with open(f'./optimal_models/{county_name}_model', 'wb') as f:\n",
    "        pickle.dump(optimal_model, f)\n",
    "\n",
    "    # 做不調參數模型\n",
    "    non_optimal_model = train_without_optimal_parameter()\n",
    "    with open(f'./non_optimal_models/{county_name}_model', 'wb') as f:\n",
    "        pickle.dump(non_optimal_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀pickle模型，預測\n",
    "import joblib\n",
    "\n",
    "county_name = '台北'\n",
    "model = joblib.load(f'./optimal_models/{county_name}_model')\n",
    "# 讀取未調參數版本的model\n",
    "non_optimal_model = joblib.load(f'./non_optimal_models/{county_name}_model')\n",
    "X_train, Y_train, X_test, Y_test = read_df(county_name)\n",
    "# 訓練時沒有用raw_time欄位，但現在要測模型(X_train+X_test都測)所以也要拿掉raw_time\n",
    "X_all_data = pd.concat([X_train, X_test])\n",
    "raw_time = X_all_data['raw_time'].to_numpy()\n",
    "X_all_data = X_all_data.drop(columns=['raw_time'])\n",
    "\n",
    "Y_all_data = pd.concat([Y_train, Y_test])\n",
    "\n",
    "result = model.predict(X_all_data)\n",
    "non_optimal_result = non_optimal_model.predict(X_all_data)\n",
    "\n",
    "# 加回去raw_time, 真實y\n",
    "result_table = pd.DataFrame()\n",
    "result_table['raw_time'] = raw_time\n",
    "result_table['LRHP'] = Y_all_data.reset_index()['LRHP']\n",
    "\n",
    "# 加回去預測結果\n",
    "result_table['y_hat_tuned'] = result\n",
    "result_table['y_hat_without_tuned'] = non_optimal_result\n",
    "\n",
    "result_table['RHP'] = np.exp(result_table['LRHP'])\n",
    "result_table['y_hat_tuned'] = np.exp(result_table['y_hat_tuned'])\n",
    "result_table['y_hat_without_tuned'] = np.exp(result_table['y_hat_without_tuned'])\n",
    "\n",
    "# 加回去hit rate\n",
    "def hit_rate(cola, colb, threshold):\n",
    "    # cola: 實際值\n",
    "    # colb: 預測值\n",
    "    # threshold: 0.1\n",
    "    if abs((cola-colb) / cola) <= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "result_table['1%_hit_rate_tuned'] = result_table.apply(lambda x: hit_rate(x['LRHP'], x['y_hat_tuned'], 0.01), axis=1)\n",
    "result_table['1%_hit_rate_without_tuned'] = result_table.apply(lambda x: hit_rate(x['LRHP'], x['y_hat_without_tuned'], 0.01), axis=1)\n",
    "result_table['5%_hit_rate_tuned'] = result_table.apply(lambda x: hit_rate(x['LRHP'], x['y_hat_tuned'], 0.05), axis=1)\n",
    "result_table['5%_hit_rate_without_tuned'] = result_table.apply(lambda x: hit_rate(x['LRHP'], x['y_hat_without_tuned'], 0.05), axis=1) \n",
    "result_table['10%_hit_rate_tuned'] = result_table.apply(lambda x: hit_rate(x['LRHP'], x['y_hat_tuned'], 0.1), axis=1)\n",
    "result_table['10%_hit_rate_without_tuned'] = result_table.apply(lambda x: hit_rate(x['LRHP'], x['y_hat_without_tuned'], 0.1), axis=1)\n",
    "result_table['15%_hit_rate_tuned'] = result_table.apply(lambda x: hit_rate(x['LRHP'], x['y_hat_tuned'], 0.15), axis=1)\n",
    "result_table['15%_hit_rate_without_tuned'] = result_table.apply(lambda x: hit_rate(x['LRHP'], x['y_hat_without_tuned'], 0.15), axis=1)\n",
    "result_table['20%_hit_rate_tuned'] = result_table.apply(lambda x: hit_rate(x['LRHP'], x['y_hat_tuned'], 0.2), axis=1)\n",
    "result_table['20%_hit_rate_without_tuned'] = result_table.apply(lambda x: hit_rate(x['LRHP'], x['y_hat_without_tuned'], 0.2), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 產製結果\n",
    "def compare_tuned_and_without_tuned_model(result_table):\n",
    "    result = pd.DataFrame()\n",
    "    result['MAPE_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: mean_absolute_percentage_error(x['LRHP'], x['y_hat_tuned'])\n",
    "    )\n",
    "    result['MAPE_without_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: mean_absolute_percentage_error(x['LRHP'], x['y_hat_without_tuned'])\n",
    "    )\n",
    "    result['1%_hit_rate_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: x['1%_hit_rate_tuned'].sum()/len(x['1%_hit_rate_tuned'])\n",
    "    )\n",
    "    result['1%_hit_rate_without_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: x['1%_hit_rate_without_tuned'].sum()/len(x['1%_hit_rate_without_tuned'])\n",
    "    )\n",
    "    result['5%_hit_rate_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: x['5%_hit_rate_tuned'].sum()/len(x['5%_hit_rate_tuned'])\n",
    "    )\n",
    "    result['5%_hit_rate_without_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: x['5%_hit_rate_without_tuned'].sum()/len(x['5%_hit_rate_without_tuned'])\n",
    "    )\n",
    "    result['10%_hit_rate_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: x['10%_hit_rate_tuned'].sum()/len(x['10%_hit_rate_tuned'])\n",
    "    )\n",
    "    result['10%_hit_rate_without_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: x['10%_hit_rate_without_tuned'].sum()/len(x['10%_hit_rate_without_tuned'])\n",
    "    )\n",
    "    result['15%_hit_rate_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: x['15%_hit_rate_tuned'].sum()/len(x['15%_hit_rate_tuned'])\n",
    "    )\n",
    "    result['15%_hit_rate_without_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: x['15%_hit_rate_without_tuned'].sum()/len(x['15%_hit_rate_without_tuned'])\n",
    "    )\n",
    "    result['20%_hit_rate_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: x['20%_hit_rate_tuned'].sum()/len(x['20%_hit_rate_tuned'])\n",
    "    )\n",
    "    result['20%_hit_rate_without_tuned'] = result_table.groupby('raw_time').apply(\n",
    "        lambda x: x['20%_hit_rate_without_tuned'].sum()/len(x['20%_hit_rate_without_tuned'])\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAPE_tuned</th>\n",
       "      <th>MAPE_without_tuned</th>\n",
       "      <th>1%_hit_rate_tuned</th>\n",
       "      <th>1%_hit_rate_without_tuned</th>\n",
       "      <th>5%_hit_rate_tuned</th>\n",
       "      <th>5%_hit_rate_without_tuned</th>\n",
       "      <th>10%_hit_rate_tuned</th>\n",
       "      <th>10%_hit_rate_without_tuned</th>\n",
       "      <th>15%_hit_rate_tuned</th>\n",
       "      <th>15%_hit_rate_without_tuned</th>\n",
       "      <th>20%_hit_rate_tuned</th>\n",
       "      <th>20%_hit_rate_without_tuned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10108</th>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0.915956</td>\n",
       "      <td>0.724726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998782</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10109</th>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.007044</td>\n",
       "      <td>0.923690</td>\n",
       "      <td>0.763098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10110</th>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.921154</td>\n",
       "      <td>0.733654</td>\n",
       "      <td>0.999038</td>\n",
       "      <td>0.999038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10111</th>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>0.907522</td>\n",
       "      <td>0.738594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10112</th>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.929273</td>\n",
       "      <td>0.749509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11108</th>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.753165</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11109</th>\n",
       "      <td>0.007085</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11110</th>\n",
       "      <td>0.007373</td>\n",
       "      <td>0.007769</td>\n",
       "      <td>0.722603</td>\n",
       "      <td>0.722603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11111</th>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.796209</td>\n",
       "      <td>0.763033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11112</th>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.006123</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MAPE_tuned  MAPE_without_tuned  1%_hit_rate_tuned  \\\n",
       "raw_time                                                      \n",
       "10108       0.004385            0.007799           0.915956   \n",
       "10109       0.004236            0.007044           0.923690   \n",
       "10110       0.004201            0.007388           0.921154   \n",
       "10111       0.004527            0.007541           0.907522   \n",
       "10112       0.004034            0.006958           0.929273   \n",
       "...              ...                 ...                ...   \n",
       "11108       0.006956            0.007449           0.753165   \n",
       "11109       0.007085            0.007779           0.740260   \n",
       "11110       0.007373            0.007769           0.722603   \n",
       "11111       0.006874            0.007060           0.796209   \n",
       "11112       0.005780            0.006123           0.807692   \n",
       "\n",
       "          1%_hit_rate_without_tuned  5%_hit_rate_tuned  \\\n",
       "raw_time                                                 \n",
       "10108                      0.724726           1.000000   \n",
       "10109                      0.763098           1.000000   \n",
       "10110                      0.733654           0.999038   \n",
       "10111                      0.738594           1.000000   \n",
       "10112                      0.749509           1.000000   \n",
       "...                             ...                ...   \n",
       "11108                      0.727848           1.000000   \n",
       "11109                      0.746753           1.000000   \n",
       "11110                      0.722603           1.000000   \n",
       "11111                      0.763033           1.000000   \n",
       "11112                      0.692308           1.000000   \n",
       "\n",
       "          5%_hit_rate_without_tuned  10%_hit_rate_tuned  \\\n",
       "raw_time                                                  \n",
       "10108                      0.998782                 1.0   \n",
       "10109                      1.000000                 1.0   \n",
       "10110                      0.999038                 1.0   \n",
       "10111                      0.998767                 1.0   \n",
       "10112                      1.000000                 1.0   \n",
       "...                             ...                 ...   \n",
       "11108                      1.000000                 1.0   \n",
       "11109                      1.000000                 1.0   \n",
       "11110                      1.000000                 1.0   \n",
       "11111                      1.000000                 1.0   \n",
       "11112                      1.000000                 1.0   \n",
       "\n",
       "          10%_hit_rate_without_tuned  15%_hit_rate_tuned  \\\n",
       "raw_time                                                   \n",
       "10108                            1.0                 1.0   \n",
       "10109                            1.0                 1.0   \n",
       "10110                            1.0                 1.0   \n",
       "10111                            1.0                 1.0   \n",
       "10112                            1.0                 1.0   \n",
       "...                              ...                 ...   \n",
       "11108                            1.0                 1.0   \n",
       "11109                            1.0                 1.0   \n",
       "11110                            1.0                 1.0   \n",
       "11111                            1.0                 1.0   \n",
       "11112                            1.0                 1.0   \n",
       "\n",
       "          15%_hit_rate_without_tuned  20%_hit_rate_tuned  \\\n",
       "raw_time                                                   \n",
       "10108                            1.0                 1.0   \n",
       "10109                            1.0                 1.0   \n",
       "10110                            1.0                 1.0   \n",
       "10111                            1.0                 1.0   \n",
       "10112                            1.0                 1.0   \n",
       "...                              ...                 ...   \n",
       "11108                            1.0                 1.0   \n",
       "11109                            1.0                 1.0   \n",
       "11110                            1.0                 1.0   \n",
       "11111                            1.0                 1.0   \n",
       "11112                            1.0                 1.0   \n",
       "\n",
       "          20%_hit_rate_without_tuned  \n",
       "raw_time                              \n",
       "10108                            1.0  \n",
       "10109                            1.0  \n",
       "10110                            1.0  \n",
       "10111                            1.0  \n",
       "10112                            1.0  \n",
       "...                              ...  \n",
       "11108                            1.0  \n",
       "11109                            1.0  \n",
       "11110                            1.0  \n",
       "11111                            1.0  \n",
       "11112                            1.0  \n",
       "\n",
       "[125 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compare_tuned_and_without_tuned_model(result_table)\n",
    "\n",
    "if not os.path.exists('./compare_tuned_and_without_tuned_model'):\n",
    "    os.mkdir('./compare_tuned_and_without_tuned_model')\n",
    "result.to_csv(f'./compare_tuned_and_without_tuned_model/{county_name}.csv')\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anfu-train-task-FhShlNTd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33fe252ea09164cd33d0f53a898497c38584bd95561420e8952c41dccaf3bb94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
